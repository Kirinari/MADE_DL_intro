{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device cpu\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_SEED = 17\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Current device {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1 = [name.split('.')[0] for name in os.listdir('samples') if '.' in name]\n",
    "names2 = [name.split('.')[0] for name in os.listdir('samples/samples') if '.' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(\"\".join(names1))\n",
    "chars = sorted(np.unique(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_ch = {i + 1: ch for i, ch in enumerate(chars)}\n",
    "id_to_ch[0] = \"-\"\n",
    "ch_to_id = {ch: i for i, ch in id_to_ch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': 1,\n",
       " '3': 2,\n",
       " '4': 3,\n",
       " '5': 4,\n",
       " '6': 5,\n",
       " '7': 6,\n",
       " '8': 7,\n",
       " 'b': 8,\n",
       " 'c': 9,\n",
       " 'd': 10,\n",
       " 'e': 11,\n",
       " 'f': 12,\n",
       " 'g': 13,\n",
       " 'm': 14,\n",
       " 'n': 15,\n",
       " 'p': 16,\n",
       " 'w': 17,\n",
       " 'x': 18,\n",
       " 'y': 19,\n",
       " '-': 0}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, dir_path, image_paths, transform=None, encode_table=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.transform = transform\n",
    "        self.encode_table = encode_table\n",
    "        self.image_paths_id = []\n",
    "        self.image_paths = image_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_to_image = self.image_paths[index]\n",
    "        label = path_to_image.split('.')[0]\n",
    "        if self.encode_table:\n",
    "            label = torch.tensor([self.encode_table[ch] for ch in label], dtype=torch.long)\n",
    "\n",
    "        with Image.open(self.dir_path + '/' + path_to_image).convert('RGB') as img:\n",
    "            img.load()\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, label)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "data_dir = \"samples\"\n",
    "\n",
    "image_paths = [name for name in os.listdir(data_dir) if '.' in name]\n",
    "\n",
    "train_paths, test_paths = train_test_split(image_paths, shuffle=True, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "batch_size = 4\n",
    "num_workers = 0\n",
    "\n",
    "trainset = CaptchaDataset(dir_path=data_dir, image_paths=train_paths, encode_table=ch_to_id, transform=transform)\n",
    "testset = CaptchaDataset(dir_path=data_dir, image_paths=test_paths, encode_table=ch_to_id, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=num_workers)\n",
    "                                    \n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 214)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAA5CAYAAAAiJwBoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAAv4ElEQVR4nO2deXTUx5XvP9Xd6m4tLbVau0BoQQsIMGvYkRmMTMyAjQE/MOBxHDsZPzuxnYnjSU5mfPI8M2f8vD5P7Ewy9jPEYQyJMRjCGBuDDDb7DpIQSEho39VSS2q1ev29P9S/37TaLSFAgOLX33N09Fuq6nfr1q1bt27dqhaSJBFEEEEEEcS3B6o7TUAQQQQRRBDDi6BiDyKIIIL4liGo2IMIIoggvmUIKvYggggiiG8Zgoo9iCCCCOJbhqBiDyKIIIL4luGmFLsQ4rtCiMtCiCtCiJ8PF1FBBBFEEEHcOMSNxrELIdRAKZAP1AIngYclSbo4fOQFEUQQQQRxvbgZi30mcEWSpApJkhzAVuCB4SEriCCCCCKIG4XmJvKOAmp87muBWYNlCA8Pl6KjowEQQtzEp28fRiqdkiThO9saqXT6YiTT6Ha7FfoC0el2u3G5XISEhKBSjYylqZHKT0mS8Hg8g/JzJGKk0ul2u6mvr2+VJCluqHluRrEPCUKIHwI/BDAajXzwwQeoVKp+jT7Y9UD3vp3rdqYb6J3v82ulG0qaQOl8/44fP059fT2JiYnDVqZ//tuZzrcNrreMG6HH997lcrF582aysrJQq9UByzx48CCvvfYar776KllZWbdMlm4k3WB5hls2B6qf719hYSElJSWkpKQMWqZ/ew+17a6Vbig0Xm+6G6XJ/xvyvUqlUgyzQHyQryVJYtOmTTz11FNVXAduRrHXASk+96O9z/pBkqT/AP4DICUlRZIrBQRkzkDMC/Qu0PtrpbvexroWXdei9WbSXYvW4eLFUN/dijreqnYbSjr5z+PxXLONDQYDDoeD3t5ehBADyvDNtMet4MVgbXCr2m2wAVr+L0kSLpcLrVY7ZPpuNt1w8OJG2k2lUuHxeFCr1f3q73A4aG1tRQihDIL+5d8obkaxnwSyhBDp9Cn0tcC6m6LmDkOSpJtm6EjHYHX0fff/Ay+uB6GhoQB0d3cPiS9D5Z9vuv8f+C2EwOl08oc//IGoqChWr149JNfWX7Jsut1u1Go1DoeDpqYmSkpKOHXqFFVVVXg8HjZs2MDo0aOHtU43rNglSXIJIX4EfA6ogfclSSq+3nJ8R6eBGliSpH7uG/mZnN///0AM8rd05HLkPP5lBsoXiG7/dINZWNeTbrBvDYZrlSnX1de68s3nX8a1aPK3xK6njjfSbjeT7np46ZtWp9MREhJCb2/vgN/1eDxIkoRG09ethsJbuR18LTp/Wb/eOvqnG6hOwy3DQ4VKpeLKlSt0dnayfPly9Hp9wL7vy5/B+qTs1ggks0PtV77X/t/0L89Xxn3T+pfldDrp6OigtLSUc+fOUVhYiCRJjBkzhrlz5/Loo4+SmJjYb91muJT7TfnYJUn6FPh0OAjxZZJ87yvs3u8pjTiY8Mv5A93L5QJK2XJDyZ22paUFg8FATEzMkBTcUGgY7nQDvR9IGH3hdrtpb2+nqqqK9vZ2DAYDY8aMIT4+Hp1O941816JJ5psQAr1e/w1Bv5k6DkTDjaYbCg2BoNfrCQkJoaen5xtl2O12jh49yr59+3A6nSxYsIDvfve7ipU/0CK3x+PBYrFw5MgR9Ho9d911FyaTCbVaTUhIyIA03ygvBspzu2VTo9Ewfvx4tm3bhtlsZvTo0QEVJEBtbS379+9nypQpTJo0Cb1eDwS24D0eDx6PB6vVis1mIyoqShmQ/fXLteror9wlScLtdmOxWLh8+TImk4nc3FzUarWyUOx2u+ns7KSyspJTp05RXFxMd3c3Y8aMYcaMGSxbtozk5GRCQ0P75fNvr+FQ7rd88fR6IUkSe/bsoaOjg/j4eIXBdrudWbNmkZiYiFqtVvxWN8IE2c/vdDpxuVx0dnbS09NDUVERFouF2tpaMjMzWbt27S2o4Z2F3W7nN7/5DUeOHKGlpUXhb1hYGBMmTGDx4sUsW7as34A6GCRJorOzk3379qFWq1myZAkxMTHKu+GyQO4khBBotVrUajU9PT1KveToj23btrFx40aEEERERFBZWcmCBQvQ6XTY7XacTicqlQq3240kSYSGhhIWFoZKpeLMmTO8+uqr9Pb2Mm7cODIyMliwYAFjx44lIyPjW8G/QJg4cSKbN2+mrKwsoBtCvq+qquK9995Dq9Xy7rvvkpOT0y+NzWbDarUSFhZGWFgYhYWF/OlPf8JisRATE8OoUaNYuXIl8fHxykzqWvBVtjabjerqas6cOUNhYSFnz56ls7OTp59+mvHjx9PV1UVDQwNnz57l3LlztLS0kJCQwPTp03n66acZPXo0ERERAT0Ot7Jt75hi96+UvJjy7rvvUlBQQH5+PgaDQUlXX1/Pm2++SXJyMvfccw85OTmKdehb5kAC4tsZAVwuF4cPH+b06dPKglhlZSUXL17E4/Hw3HPPfWPW4GtRyLOGa9XrVmAo1pH83z9tV1cX+/bto7e3l6SkJIxGIzabjfr6eg4dOkRrayv33XdfP0H05Z2/e8Hj8dDW1sbx48cpKirC4XDw8MMPo9PpvjFLkvMGmur6W2uDWVdDsSKHms7/XSCeQZ/FrtPpsFgs/dKWlZXxhz/8AYCf/vSnTJ8+ndLSUoxGI/v27WPLli1KqKTb7Uar1TJu3DjWrVtHZmYmra2t6HQ6IiIiqKqq4sKFC+zbt49HHnmEhx9+GKPRGNAyhf4uG9//vu0VyAoeCUhNTSUiIoLi4mLuvvtuJRrJl3a1Wk17ezt2ux2NRoNOp6O9vZ0LFy7Q1tZGeXk5paWldHd3k5aWxhNPPEFTUxO9vb24XC4uXLjAgQMH+Prrr/nBD37AwoULlcVaXwRy90iSRG1tLRs3buTgwYPU1NQoMmwymSgvL+eXv/wl7e3tREVFMXnyZB555BFSUlKIiooK6FGQ8/ta6zC4DN/oBtLbrtgHcxfU19fz6aefsmzZMp588kklrawQuru7OXz4MJs3b0YIQV5eHvPmzSM6OhqNRtPP9yVb9G63G+ib/tntdrRarfKuo6ODgwcPKiN+fHw8eXl5ZGVlkZeXR0dHB11dXcTFxREWFvYNoQP6zSh6enpQqVREREQo0z//jjXYdDqQsgvEP//01+q4/nn+5m/+hqlTpzJq1Ch0Oh3d3d1s3LiRjz/+WFmdH0gJy1Zqb28vWq0WnU6H0+mkvr6ejo4OXC4XarVaGah7e3tpb29Hq9USHR2NzWYjOjpacTXI5cqCLuf195sOVKeBeDnUdENJ6/F40Ov1ZGRkUFFR0S/fkSNH6OzsJDk5mYkTJxIWFkZeXh6SJNHV1YVOp8Pj8dDa2kpzczM2m43KykqMRiMrVqygvb0dl8vFY489RmxsLPv376e8vJza2lo6OzuJiYlRjAuZ9/X19VRVVTF27Fji4+P7uW1k2Qy0duRviNyMbF6Ln4PJpiRJREVFkZ6eTnFxMR6PR+m/Mr1yX21rawP6Bla9Xs+ZM2f453/+Z2VB0uPxKFb1xIkTmT9/PrNnz0aSJNrb29m1axdbt27llVdeQaPRkJeXp1juMl2yrNntdlwuF5IkYbPZOHz4MMeOHaO8vJyQkBCMRiOxsbGkpaVhMpmYNWsWOTk5GI3GfvI8kBzJ/Pd3wQzEy0DPh4oR44qRJInGxkYcDgfTp09XGs3tdlNdXY3b7Uaj0XDo0CEqKytJS0ujtLSUY8eO8aMf/Yjk5GSFWR6Ph6qqKr766is6OjpYvnw5qampnD59GrPZzIQJEwgPD8flcqHT6Rg7diyTJ08mKSmJSZMmERcXh0qlYvfu3Vy4cIH09HTWrFmDXq9XLAu5kdxuN1euXOHDDz/k5MmTaDQa5s2bx5NPPklsbOyIs5RiYmJYu3atYlF4PB7OnTtHQUEBubm5bNiwAa1W2886tNlsdHZ2Eh0dTWhoKCdPnuTzzz8nNDSU/Px8zGYzer2e0NBQwsPDFV/k8ePHKSkpwWazERISgsFgoKqqinvvvZclS5YonUGSJJxOJ93d3TidTuLi4tBoNEN2B91qqFQq9Ho9a9eu5ZVXXqG1tZX4+HicTieVlZW43W5aWlp44YUXiI2NZdGiRdTU1CBJEomJiTgcDsLDw4mKiuLKlSu4XC4uXrxIc3MzpaWldHZ2UlBQQFxcHC0tLZhMJhISEmhsbMRgMGAymRRF1tzczI4dOzCbzWg0Gtrb25EkiYyMDGXK73K5cDgcSJKkrA3IG9rutDzK31er1UycOJGdO3fS1tZGQkICKpUKi8XCrl27OHv2LOPGjaOxsRGAsLAwtFot6enpPP3008THxxMTE0N5eTmbN2+muroas9lMfHw8BoOBkJAQTCYTa9as4cqVKxw6dIgdO3YQGRmJEAKj0YjD4aClpYX6+nqqq6upqanBbDbjcDhob2+nt7dXMeyysrJ4/PHHmTZtmqLIfUO3RwJvfTFiFLtKpaK2tpaIiAhSUlIU3+3LL7/M+fPnWbJkCRUVFVy4cAGXy0VNTQ3r16/nvvvu41e/+hXZ2dnMnDkTgPPnz7Nv3z4aGhrQ6XSUlpai1+upqamhqamJ0aNHk5SURF1dHS0tLRiNRrq6uggLC+PSpUvU1NRQV1fHrl27FD/0e++9B6BYbpMmTSI5OZljx47x4osv0tjYSEZGBiqVio8//pjp06ezdOnSAes70Gr/rQ7rkq0T2SqWp5uRkZH85Cc/ITc3F4vFQlVVFZcvX6awsJDKykp6enr4yU9+QlxcHO+88w5FRUVotVoKCgqYMmUKAAaDAY1GQ1NTE2fOnOHIkSPU1dUxc+ZMzp49y+nTp4mKimLUqFEsWLCAkJAQGhoaKC4u5ujRo5SXl6NSqVixYgUrV64kLCxswPoPhTfDxTuZV9nZ2RiNRo4fP87ixYt59dVXOXz4MEIIHA4HV69epa6ujo6ODubPn8/cuXMxGo1ERkYSFRVFUVERv/jFL9BoNDz33HNkZmby29/+li1btpCens6iRYtISkqisbGRTz75hH/4h39Ao9Ewbtw4pk2bxpgxYzhw4ABnz57lqaeeIj4+nr1793L48GEmTZrEggULiIyM5MyZMxQVFREWFsaaNWuYOHGiMlgPF26Gt/J6Q1ZWFlarlXPnznHPPfdgsVh46623+PrrrzGZTFRVVWE2m5U8zc3N6HQ6pkyZgsPhwOVyERoait1ux+Px0NLSwqFDh3C73djtdhwOB42NjbS0tCCE4ODBgxQVFWG325EkSbHCDQYD1dXVOJ1O8vPzmTdvHqmpqRw5coSDBw8yc+ZMnnjiCWXglI0O393fI0mpwwhQ7L7KLT8/n6ysLBISEpSpUVFRER0dHRw5coTU1FT+5V/+hePHj/PJJ5/w5z//mZaWFi5dusSZM2coKSnh7rvvBqCjowO3241er2fevHlkZmby4YcfotFo+PnPf05qairbt29n586ddHZ2cvnyZU6dOkVsbCxRUVG0trZy5coVWltblU0ENpsNIQTx8fEsXLiQzMxMtm7dSk1NDY899hirV69Gr9dz9epV0tLS+vmkZf9aIN+8b4cLFCI3VB+pbzqPx0NpaSk6nQ6DwaBYbjqdTol8sdvtbN26ldbWVv7u7/6OiRMncvHiRTZt2sT58+fp7e0lLCyM5ORkpkyZQnx8PAcOHODixYskJSXx+OOP09bWxqeffkpzczMmkwmz2UxhYSGHDx+mqamJ++67jzlz5mAymSgrK6O7uxuj0YjH42HLli1s376d2tpaxT1mtVrp6uoiNTWVBQsWDOi6G4hP/umu5X4ZCj/lmUtoaCh5eXns2bOHUaNGUV1djcPhUDr7hAkTWLZsGXl5eRiNRtRqtWJp2+12CgsLcTqdrFq1iuzsbIW/BoOBHTt28OWXX7JmzRoeeughHnnkEWVwDQkJQaPRsHfvXsrLyzEajZw5cwaVSkVrayvFxcXU1PSd7vHVV19RUVGBw+FQBpxnn32WMWPGKLO063HbDZbmevkpw26386c//YnS0lJcLhf/9m//xmeffYbZbKa8vBzoW7R0Op3YbDYA6urqePrpp5WQUnkhWtYTQggOHDjAl19+qcyqZf739vYiSRJJSUlYrVY6OzvJzs7mmWeeYeLEiZSUlPDv//7vJCYm8oMf/ICsrCxUKhVms5mPP/6YiooKfve739HW1obJZOLee+9lxowZAcNaB+LX9bivhgN3XLH7IioqiilTpgT0z2k0Gp555hlCQ0M5fPgwkiTR0dGBx+MhNTWVS5cukZKSwpo1azhw4AAulwuVSqUICPQtwI4bN45Ro0ZhNBoJCwujrq4OSZIoKysjMjJSiVqYM2cOTqeTCxcukJSUxH333YfNZmPv3r1cuXKF3bt3ExcXR1lZGVlZWVRVVfHrX/8atVqNWq1Go9Gg1WrRarUYjUaio6OJiYkhOjqayMhIIiIi0Ov1hIeHExoaqizO+YZiDuY7HgxCCKxWK6+++io1NTWEhoYSERGhWI5RUVHEx8fjdrvZv38/BoOBwsJCurq6+Pzzz7lw4QJ6vZ7ly5ezevVqkpOTCQsLw2q1cunSJRwOBzk5OSxdulSJQd68eTM2mw1JkrBarZw6dYq0tDTmz5/P6NGjKSsrIz09nfPnz+N2u/n888/ZsmULbW1tLFmyhPXr11NaWsobb7zB1atXKSwsZMGCBYPW3X9m4+9XlgdMObb8Rs/W8S1n1apVZGVlsXnzZkXBCCEYM2YMf//3f4/RaMTpdCoLphs3bsTtdtPW1sbRo0dZtGgRf/3Xf41arSYiIoKHHnqI/Px8iouL+fDDD3n33XdpaWnh8ccfZ8GCBTQ0NNDQ0IDBYMBisZCdnc3q1avRarWcP3+ew4cPY7VacTgcbN26FaPRyJw5c6irq6O8vJzjx4/T0NBAWlraoAPeYLI00P31lOffnysqKqiuriYrKwuAy5cvY7FYUKlUjB8/nqSkJHQ6HRcvXqSiogKDwcD999+PyWRCr9crUUX/9V//RVlZGU888QTZ2dno9Xo0Gg0ajYaysjK++OILTpw4gdFoZN26dbS3t7Nt2zZsNhuFhYXExcVRXV3NqFGjmDJliuLSdbvdxMfH09LSQnV1tTK4q9VqJZIpOzv7umbXQxlQh8LLoWBEKXZfyFMlrVaLEIKJEydy8uRJPvnkE8aMGUNmZiaXLl3C4/EwefJkiouLuXLlChaLhYqKCiIjI0lMTKS4uJi6ujrMZjNarZbk5GSio6NRq9V85zvf4W//9m8xm810dnbidDqprq5mz549aLVaNBoNERERzJs3j7/6q78iIyOD9vZ2ysrKsNlsymr9ihUreOqpp1Cr1dhsNnp7e3E4HPT09Ch+OovFQltbG5WVlXR1ddHT09MvWsJutwN9OxwjIyPJzs5mw4YNhIWF3RDv9Ho9Tz31FI2NjbS1tdHa2kp7eztms5n6+nqOHTtGR0cHkiRhsVj46KOPlLwy7y0WCwUFBcTHxyvx1dXV1Yq/vKenB71ez/Tp05WZT09PD62trbhcLhISEpSF7bi4OGVQqaiooKqqivr6ejIzM1m/fj3jxo1TrDGbzYbZbKa7u5vIyMiAdZRnQHLssi/t8uKUfASA3W4nOjqa2NjYG5JFeaCQw2zj4+Pp7Oykurqa+Ph4mpqaMJvNfPDBB2g0Gjo6Oli4cCGLFy+murqaAwcOKBb0oUOHqK+vZ926deTl5WEymYiNjSU9PZ3ExERee+019uzZQ2JiIosWLcJsNnPkyBEuXryIJEksX76cvLw8YmNj+c53vkN0dDTbtm2jpaWF6dOnKwOAvA7U2tpKeXk506dP77dH4U4iJCSEn/3sZwBKlMqnn37KG2+8gUaj4cknn1Tcqm+//TaVlZVERkbyyCOPEBcXp7RxaWkpZrNZmeXIazatra0cOnSIXbt2UVZWRlRUFI8//jiLFy/m8uXL1NfXU1JSwv79+0lISKCpqYnk5GRSUlKw2+2Eh4ejVqtJTEzkxz/+sTKIHD58mK+//pri4mJOnjxJWlqaElc/0jCiwh39FyNkq1eeZlVXV/PDH/6QqVOn8tJLL1FSUkJ7ezvz588nJCSE2tpaKisrqa+vJyoqimnTplFaWkptbS09PT24XC7S09OVDjp+/HhycnLo6uqio6OD8+fPs2nTJiWSw2w209zcrCxouVwujEYjERERdHd3U11djcFgwO1243Q60Wq1REREYDAYgMCH+/hO2zwejxJLL5dht9uVQSbQSnug6Vqge51Op3QOOY/8DavVyqFDh3jrrbeIjIxk7dq1aDQaKisr2b17txKRUFxczOnTp3E4HIoClf2TcvRGTEyMEkkghGD//v3Y7XYsFgt1dXUcPXqU0NBQampqqKysRKVSUVdXp+Srra3lnXfewWKxcOXKFdrb24mLiyM0NJTy8nL0ej1WqxWr1YrFYqG7uxur1UpPTw92ux2bzYbD4VB453Q6cTqdCg9CQ0MJDQ1l5cqVSrRKIFkcynRYkiQuXrzIq6++Snt7Oy+88AIXLlxg27ZthIeH89RTT2E0GrFarbz11luEhYXxwgsvsGLFCoqKijh58qSiFEJCQpg2bRpRUVGKJZiZmcny5cv54IMPKC0tJTk5mdzcXAClXSorK5UZaHR0NJmZmUiSxMSJE1m1ahULFy7E6XSyefNmdu7cSXV1NZs2baKwsJCsrCymTZtGamoqJpOp3+K1f50DnYUTaHdnoOiOwSxOuZ+Hh4f3KzclJUWJttq8eTNarZacnJx+Ljp5Y5BKpaKjo4NNmzYxevRoRX7lxdedO3eybds2PB4PixcvZuHChcydO5ewsDAiIyMZPXo0ly5dory8nB07dhAXF8eUKVMwGAxERUUpNCUkJPDkk08qtKekpNDV1cWJEyeor6/HZrMp+sl/RuLLo8HkbTDIdNwIRlS4I/Q/KsD3KNW0tDReeeUVTCYT7e3tNDc3A31RKePHj1ee7927l56eHnJzc8nMzCQmJoaTJ08SGRlJenq6YnnKeYUQREZGEhkZiVqt5t1330WSJMxmM42NjcoCjbyLMDY2VhEiecNKcXEx9fX1/aZm/oIfSPnKLptAgjEUBe7/HV8EWtRRq9U4nU62bNnCrl27sNvtPPjgg6xfvx4hBBaLhZMnT1JVVcX999/P97//fUWhWiwWzGYzX375JXv37lWsptbWVlpaWpRIgoiICITo20599uxZrl69islkorOzk9bWVtxuNx0dHej1elwul1Im9G3bnzRpEiaTiZKSEioqKggPD1fcSAaDgfDwcBISEggPD1cGUtmVFRERoWxUkS1WXx4HiuseqmtBCMHXX3+tKOxf/epXTJs2TXHlWa1WNBqNIiurVq1i//795OfnM3v2bGbOnMmyZct4//33+eijj5Rdv0ajEegb5E0mk2ItlpSUMH36dGbNmkVJSYkS7rdnzx6MRiPPPfccBoOB3t5ebDYbNTU19Pb2otPpiIqKYurUqXz22WdERUXx6KOPMnXqVEpKStixYwdNTU2Eh4eTlZXFnDlzGDNmjBIJJrus/N1bvmGUgTCQbAZSdr6yKSv6iIiIfiHEO3fuVIwDWTarqqqYNWsWPT09bN68mdraWl566SVlv4vD4eDYsWPs2LGDnp4eNmzYwKpVq4iLi1OMuXHjxtHT00NzczNXr16lqKiI6dOnExUVxV133dUv7NK/XhkZGcoGNavVSnh4eL86DEWOBuPZ9QwO18KIdcXY7Xbee+89qqurAWhubqagoIDExETOnDnD1atXEUIoU6ixY8dy/Phxjh49ikql4p577iEtLY3U1FTq6+tpbW0lNzeXpKQkAMVKkuPcPR4Pzc3NdHV1kZCQwKJFiygoKKCxsZGqqirsdjuxsbHK4qNeryc5OZn6+nq++uoruru7eeCBB4iJiSEsLIyUlBQyMzPvGP98IfsH5V2nu3fvVs4Wl60ilUqFwWBg3rx5VFdXc/HiRbq7u0lKSiIxMRGr1UpTUxMmk4lLly7R1tZGeno6c+bMobS0lD179qBWq0lNTWXSpEns3LmT9vZ2pk2bRmhoKDExMezatQuz2cyiRYu45557eP3113G73Tz66KMsWLBACe2rr6+noqKC/Px8xRXjH5sNAy+gDnZ66I3iyJEj/Ou//ivp6en87Gc/Y+zYsQghiImJQaVS0dvbS3d3t3I/duxYtm7ditlsJiYmBrVaTXJyMqNGjVLkVpIkTpw4QUVFBcnJyYo8dXR0EBUVhUajwWKxcOzYMcaPH4/D4eDUqVNs376d3NxcHnjgAUaPHo1Wq8Vms9He3o5arVb2D5jNZpKTk0lLS2PixIlMmDCBNWvW0NnZSVNTE0VFRezcuZOmpiZCQkLIzc1l0qRJ5ObmEh0d3S8qyfeY2eGEr3WclJREVVUVV65cwWAwUFFRgcvlUtpv4sSJOBwOfv/737N7926effZZRo8eTUNDAydPnqSzs5ODBw9SW1tLSkoKMTExSqinHDotSRLjxo1TwqFbW1sJDw8nJydHcVX5BzzIzy5dukRraysxMTHKIODLm+HwjQ8XRowrxhcul4tNmzaxZ88eYmJiaG5uxmw2s2XLFjo6OpRRMyEhgby8PLRaLXPnzuXUqVM0Nzej1WpJSEggPT2dhIQEZUFTXsSU0d3dTVNTEz09PZSWlnLgwAE8Hg8rV67kwQcfJCwsjJKSEmUlPSEhgczMTDQajeLqSU1N5cSJE5w6dYpz584pls29997LG2+8EdAHN9wLJQPBdxZktVr5zW9+w2effcbUqVMpLi7G7XYrG6+gb4F6+fLlSkjd+++/z5IlS7BarezZs4fw8HB+/OMf88gjj7Bp0yb27t3LgQMH0Gq1SgeS9wXk5uZSWFjIwYMHCQ8PZ/HixSQkJNDW1kZDQwNjx45l2bJlfPDBBxw8eJC4uDiEEBQVFXHixAllT4Ecd+zfcfwtcP/6DtW9EohngSyplJQU7r33XtavX09CQoKSJiEhgZCQEFwuF01NTcoipcFgwGAw8Oabb7J27VrS09Opq6vjq6++QqPRMGnSJCVc8ZNPPqG3txeDwUBnZyc2m43Y2FiSkpLYu3cvbrebdevWKfsuTp8+rew7kN0HNTU1FBQUMHnyZGJjYzlx4gRdXV0sXbqUnJycfgOe0WjEaDSSk5PDgw8+iM1mU6Jrjh49yubNmwkPDyctLY0ZM2aQnZ2tuMcCtcXNQp41L126lI0bN9LW1kZBQQGZmZmsWLGCt99+G7vdTkNDA21tbXz00Ufo9Xrq6+v5p3/6J86ePUtLS4tiTGm1Wurr63njjTc4ceIEWVlZJCYmotfrSU9PJycnh1mzZlFcXMz27duJi4tj1KhR/WYrKpWKpqYmurq6kCSJwsJCtm/fjsViYc2aNcydO3fAjV/DyZdb6ooRQlQCXYAbcEmSNEMIYQL+CKQBlcD/kCSpfSjE+t/7dia328327dv54x//yN13301aWhq/+93vCAsL45e//CUWi4WGhgYkSSI7O5tp06ahUqmYP38+GzduxGw2I4RQfN2rV68mPj4evV7P1KlTle2+LpeLU6dOsXfvXuW0OZVKxfr161m6dCkmk4kFCxbQ1NREbW2tUq4cQtnY2Ehubi75+flcvnyZlpYWxRfocDhISEjA6XT2U+w34oMbjF8DuW/8p7tdXV28+eabSjhdXl4e7777LpmZmcoBTPKO0ZycHJ555hlef/11tm/fzmeffaYshD722GNERETwwAMPkJyczGeffUZlZSUzZsygo6OD3bt3093dzYQJE9DpdCQnJ9PR0cGUKVOYNm0aGzdu5OLFi4SEhBAZGcn3v/99rl69yuHDhykuLkYIQVRUFHfffTdLlixRzhDxV9gDyc5gfBuK7A30XpL6TuR79tlnv7FpKjExkdTUVNLS0hS3ikznhg0beOmll3j++eeJj4+nvb2d1tZWFixYwNq1awkPD2flypXk5ORQWlrKl19+icvlIiIigvz8fGw2GwUFBcydO5d58+YpBsvJkyfRarVcvXqVqVOnkpCQQHFxMdXV1bz44ouYTCYuX75MRkYG999/P7GxsQPuj1Cr1RgMBiIjIxk7dizLly9X4r9LSko4evQoH3zwAWq1mvT0dGbPnk1ubi6jR4/+Bi+GIpsDtYlKpWLlypUYDAbOnz9PUlIS+fn5xMfHU1RUxLlz56irqyMzM5POzk46Ojr47W9/iyRJREREMHXqVCZPnkxGRgYTJkygtLRU2Uvx5ZdfEhoaisFgUPgtK3i9Xq+E4/q7iDweD6+//jqlpaW0tbURGxvLj370I1asWEFiYqJCdyAMVS6vZXTc6Gzzeiz2v5IkqdXn/ufAfkmSXhZC/Nx7//dDKWiwzvfFF1/w/vvvM2PGDJ599lmKi4sVX7ZarWbRokX9pj6yJZKUlMTixYupqKggIyODmTNnolKpuOuuu5g0aVJfZb2+VkAR1NTUVJqampg3bx5jx45l5syZJCUlKWVu2LCBnp4exdKfMGECs2fPprm5GY1GQ1JSEqmpqf1i1GUBGWzn5FAV/FAxUNr29nbefPNNjh49yrp16/je975HSEgIr732GqGhod+wbiVJYvHixcTGxlJQUEBHRwdZWVncc889pKSkKDvu8vLymD59OlarFaPRyLFjx7BaraSnpxMTE6PMlBISErBarQpvZOu+paWFOXPm8PLLL/PFF19QVlZGdnY2kydPJjU1td8ZKdfLC7keN5Iv0Pf8XT++71JSUvj1r3+trN34WlhpaWm8/PLL/PnPf+bo0aMkJSWxcuVKVq5cSVxc36+cJSQkEBcXx8KFC1mxYoViIUZHR/PFF18we/Zs1q5dq1jLU6dOZcKECVitVtxud7+jhLOyspg3bx7FxcWMHTuWhx9+mLvuuuu6Zyx6vZ60tDTS09NZunQpdrudpqYmysrKOH36NMeOHeOnP/3pgBFLg/HS/16WP5VKRVRUFKtWrWLlypWKTxzgpZdeorm5GYfDAcDUqVPp7u4mPj6e3Nxc5s2bx7hx4/rJs8PhoKamhtLSUmXHuU6nY9y4cajVaiwWC8XFxcTFxTF58uR+vnX5u9HR0cybN4/Y2FhlA2R6eroSFj2QwTFQXa+lwAe7v17cjCvmAWCh9/r3wAGGqNgHwsmTJ3n77bdJS0vj+eefV7ZWh4aGYrVaqampYdq0af3iiuXRVa/X8/zzz+PxePod1Qn9R1VZ8crhTA899BB2u52wsDDCw8PR6XTKaK3T6b7x03NGo5EXX3xR2VwiKzrfNL4H/dwpCCFoaWnhrbfe4vjx43zve9/j4YcfVnbNaTQaJSzQX6AlSWLGjBnKngL/7f0yD8PDw5XOPXfuXMaOHYtarVaOFairq+M///M/iYyMxGw209LSouwsNhgMijtt3bp1SlSRb4e+VVPc4YRarVaOd/Y92EmW0eTkZB577DE2bNigKE15TUPmu8zb5ORkpVy73U5+fr7iwpKjQ1QqlbJAK888p0+fzvHjx2lqamL+/Pls2LBBWcgdyqYkX8hyIH/L7XYTGhpKWloaGRkZ3HvvvTgcjmELnRzIwpd5KMuA3A89Hg/vvPMOHo9H2XDnf5S3JEmEhYWRk5NDdnY2+fn5yu7ThIQEOjs72b9/P6dPn2bWrFmYTKZvyD9AeHg4GzZsUOory6bv4vJIxVAVuwTsFUJIwO+kvp+7S5AkqcH7vhFICJRR+PzmaXR0dL+fIfMf9SwWC6NGjeKFF14gLi4Oj8dDQkKCEjNdW1urxDr7nnUiC4Rv6JFvOt/vyZEw8kl78gDg22Dw3wsnvm4N6OvI8rkovlM2/zr5/x9oWjaUd/7KQu548rd9Zwly+u7ubt544w1Onz7NY489xpo1a5TFnkB55Dr4HjjlO8Nxu90KL+VjaH2f63Q6UlNTlfJcLhc2mw2Xy0VjYyNOp5P4+Hjmz5/PrFmzSE1N7efP1Ov134hDD9SG/laS/4B6rXSBeO7PS998/tf+Zcr5/ZWCTI+8UU6WF7kceVHQv13lZ7JREah9fGVNrVYzefJkdDodvb29eDweJe5arlMgHg4mc3IeOZ/cZ+R28T2ewH+WOhTZlOHff/3pk8vxbwfZvSk/95UX/2fQd87MmDFjlPu9e/eyceNGQkJCWLp0KeHh4YpukOn3NQp9Bw/fdzJfAvXTQHW9VrpAbeOrk64HYiiZhBCjJEmqE0LEA18APwZ2SZJk9EnTLklS9EBlAIwaNUqSj8MNBNlH7Xtcr8fjoa6uDqfTidFoxGQyyd8bjN6h1Omm09zs+5spQ95R66t8feFwOGhoaFBmJoF+uOFmabhWGjm2XO78cpx5RESEEip2s98YjveS1LeL2feo4Rv9xrXS3ArZtNls1NX1/dxwUlLSN3h7q+gY6L28Kcx31ny7aRgsjdlsxmw2ExkZSXx8/B3l1VDet7e384//+I+nJUmacU1C5PKudzQQQvwK6AZ+ACyUJKlBCJEEHJAkKecaebuAy9f1wduPWKD1mqnuPP4S6AzSOHz4S6AzSOPwwZ/OVEmS4oaa+ZquGCFEOKCSJKnLe30v8BKwC3gUeNn7f+cQvnf5ekadOwEhxKmRTiP8ZdAZpHH48JdAZ5DG4cPN0jkUH3sCsMM7VdAAH0qS9JkQ4iTwJyHE40AV8D9ulIgggggiiCCGD9dU7JIkVQCTAzxvA+65FUQFEUQQQQRx47jd8WT/cZu/dyP4S6AR/jLoDNI4fPhLoDNI4/Dhpui87sXTIIIIIoggRjZG/g6QIIIIIoggrgu3TbELIb4rhLgshLgi+o4guCMQQrwvhGgWQhT5PDMJIb4QQpR5/0d7nwshxL95ab4ghJh2m2hMEUJ8KYS4KIQoFkI8O9LoFELohRAnhBDnvTT+L+/zdCHEcS8tfxRCaL3Pdd77K973abeaRh9a1UKIs0KI3SOYxkohRKEQ4pwQ4pT32Yhpb+93jUKIbUKIS0KIEiHEnBFIY46Xh/JfpxDiuRFI50+8/aZICLHF25+GTy7lnU238g9QA+VABqAFzgO5t+PbAWjJA6YBRT7PXgF+7r3+OfC/vddLgT2AAGYDx28TjUnANO+1ASgFckcSnd5vRXivQ4Dj3m//CVjrff5b4H96r58Cfuu9Xgv88Ta2+d8BHwK7vfcjkcZKINbv2Yhpb+93fw884b3WAsaRRqMfvWr6dsWnjiQ6gVHAVSDURx6/N5xyebsYPAf43Of+F8AvbndD+3w/jf6K/TKQ5L1Ooi/eHuB3wMOB0t1mencC+SOVTiAMOAPMom9Thca/3YHPgTnea403nbgNtI0G9gOLgN3eDjyiaPR+r5JvKvYR095AlFcZiZFKYwCa7wUOjzQ66VPsNYDJK2e7gSXDKZe3yxUjV0RGrffZSMFA597ccbq9066p9FnEI4pOr4vjHNBM31ET5UCHJEmuAHQoNHrfW4CYW00j8H+AFwD5RLaYEUgj/Pd5TKdF3/lKMLLaOx1oATZ63Vrvib4NiyOJRn+sBbZ4r0cMnZIk1QGvAdVAA31ydpphlMvg4qkfpL5hcUSECgkhIoCPgeckSer0fTcS6JQkyS1J0hT6rOKZwLg7SY8/hBDLgGZJkk7faVqGgPmSJE0D7gOeFkLk+b4cAe2toc+F+e+SJE0FrPS5NBSMABoVeP3T9wMf+b+703R6/fsP0DdYJgPhwHeH8xu3S7HXASk+96O9z0YKmkTfeTd4/zd7n98xuoUQIfQp9f+UJGn7SKUTQJKkDuBL+qaPRiGEvPHNlw6FRu/7KKDtFpM2D7hf9P1QzFb63DFvjTAaAcWKQ5KkZmAHfQPlSGrvWqBWkqTj3vtt9Cn6kUSjL+4DzkiS1OS9H0l0LgauSpLUIkmSE9hOn6wOm1zeLsV+Esjyrvpq6Zsi7bpN3x4K5HNvoP+5N7uAv/GunM8GLD7TuVsGIYQA/i9QIknSGyORTiFEnBDC6L0OpW8NoIQ+Bb96ABpl2lcDBV7L6ZZBkqRfSJI0WpKkNPpkrkCSpPUjiUboO49JCGGQr+nzDRcxgtpbkqRGoEYIIR/0dw9wcSTR6IeH+W83jEzPSKGzGpgthAjz9nWZl8Mnl7dxIWMpfdEd5cAvb9d3A9CxhT6/lpM+K+Rx+vxV+4EyYB9g8qYVwDtemguBGbeJxvn0TRUvAOe8f0tHEp3AXcBZL41FwIve5xnACeAKfdNgnfe53nt/xfs+4za3+0L+OypmRNHopee8969Y7h8jqb29350CnPK2+SdA9Eij0fvtcPos2iifZyOKTuB/AZe8fecPgG445TK48zSIIIII4luG4OJpEEEEEcS3DEHFHkQQQQTxLUNQsQcRRBBBfMsQVOxBBBFEEN8yBBV7EEEEEcS3DEHFHkQQQQTxLUNQsQcRRBBBfMsQVOxBBBFEEN8y/D93XujZZASsZgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16, 17,  4, 15,  9])  tensor([ 6,  9, 10, 13, 11])  tensor([12,  2,  4, 18, 16])  tensor([10,  1,  1, 19,  4])\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.__next__()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images), labels)\n",
    "print('  '.join('{}'.format(labels[j]) for j in range(batch_size)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        self.linear_1 = nn.Linear(832, 128)\n",
    "        self.lstm = nn.LSTM(128, 32, bidirectional=True, batch_first=True)\n",
    "        self.linear_2 = nn.Linear(64, 20)\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        bs, _, _, _ = x.size()\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = x.view(bs, x.size(1), -1)\n",
    "        x = self.linear_1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x, h = self.lstm(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        loss = None\n",
    "\n",
    "        if targets is not None:\n",
    "            log_probs = nn.functional.log_softmax(x, 2)\n",
    "\n",
    "            input_lengths = torch.full(\n",
    "                size=(bs,),\n",
    "                fill_value=log_probs.size(0),\n",
    "                dtype=torch.int32\n",
    "            )\n",
    "\n",
    "            target_lengths = torch.full(\n",
    "                size=(bs,),\n",
    "                fill_value=targets.size(1),\n",
    "                dtype=torch.int32\n",
    "            )\n",
    "            \n",
    "            loss = nn.CTCLoss(blank=19)(log_probs, targets, input_lengths, target_lengths)\n",
    "\n",
    "        return x, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer =  optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, test_loader, encoder, num_epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # train\n",
    "        model.train()\n",
    "        sum_loss = 0\n",
    "        for images, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            targets = targets.to(DEVICE)\n",
    "            images = images.to(DEVICE)              \n",
    "            train_pred, loss = model(images, targets)\n",
    "            loss.requres_grad = True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            loss.detach()\n",
    "\n",
    "        train_loss = sum_loss / len(train_loader)          \n",
    "        train_losses.append(train_loss)         \n",
    "\n",
    "        # validation eval                     \n",
    "        model.eval()\n",
    "        sum_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, targets in test_loader:\n",
    "                images = images.to(DEVICE)\n",
    "                targets = targets.to(DEVICE)\n",
    "                val_pred, loss = model(images, targets)\n",
    "                loss.requres_grad = True\n",
    "                sum_loss += loss.item()\n",
    "\n",
    "        val_loss = sum_loss / len(test_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch: {epoch + 1}, train loss: {r4(train_loss)},  val. loss: {r4(val_loss)}\")\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2E-3)\n",
    "num_epochs = 90\n",
    "\n",
    "train_loss, val_loss = train(model, optimizer, trainloader, testloader, label_encoder, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_loss, val_loss):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_loss, label = 'training')\n",
    "    plt.plot(val_loss, label = 'validation')\n",
    "    plt.grid()\n",
    "    plt.xlabel('Epoches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_losses(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(batch_outputs, encoder):\n",
    "    predictions_labels = []\n",
    "    for j in range(batch_outputs.shape[1]):\n",
    "        model_output = batch_outputs[:, j, :].unsqueeze(1)\n",
    "        \n",
    "        model_output_permuted = model_output.permute(1, 0, 2)\n",
    "        model_output_converted_to_probabilities = torch.softmax(model_output_permuted, 2)\n",
    "        model_output_BPA_applied_gpu = torch.argmax(model_output_converted_to_probabilities, 2)\n",
    "        model_output_BPA_applied = model_output_BPA_applied_gpu.detach().cpu().numpy().squeeze()\n",
    "\n",
    "        prediction_ctc = []\n",
    "        for n in model_output_BPA_applied:\n",
    "            if n == 19:\n",
    "                prediction_ctc.append(\"_\")\n",
    "            else:\n",
    "                c = encoder.inverse_transform([n])[0]\n",
    "                prediction_ctc.append(c)\n",
    "\n",
    "        model_ouput_without_dublicates = []\n",
    "        for i in range(len(prediction_ctc)):\n",
    "            if i == 0:\n",
    "                model_ouput_without_dublicates.append(prediction_ctc[i])\n",
    "            else:\n",
    "                if model_ouput_without_dublicates[-1] != prediction_ctc[i]:\n",
    "                    model_ouput_without_dublicates.append(prediction_ctc[i])\n",
    "\n",
    "        model_ouput_without_blanks = []\n",
    "        for e in model_ouput_without_dublicates:\n",
    "            if e != \"_\":\n",
    "                model_ouput_without_blanks.append(e)\n",
    "        prediction_label = \"\".join(model_ouput_without_blanks)\n",
    "        predictions_labels.append(prediction_label)\n",
    "\n",
    "    return predictions_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluations(model, test_loader, encoder):\n",
    "    model.eval()\n",
    "    cer_loss = CharErrorRate()\n",
    "    predictions = []\n",
    "    pred_labels = []    \n",
    "    test_labels = []\n",
    "    test_img = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            test_pred, loss = model(images, targets)\n",
    "            predictions.append(test_pred.detach())\n",
    "\n",
    "    for pred in predictions:\n",
    "        pred_labels.extend(decode(pred, encoder))\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        for ind, label in enumerate(labels):\n",
    "            label = label.type(torch.int).tolist()\n",
    "            test_labels.append(''.join(encoder.inverse_transform(label)))\n",
    "            test_img.append(images[ind].squeeze())\n",
    "      \n",
    "    test_cer_loss = cer_loss(pred_labels, test_labels).item()        \n",
    "    test_result_summary = []\n",
    "    for ind in range(len(test_labels)):\n",
    "        img = test_img[ind]\n",
    "        summary = dict()\n",
    "        summary[\"data\"] = img\n",
    "        summary[\"char_err\"] = cer_loss(pred_labels[ind], test_labels[ind]).item()\n",
    "        summary[\"label\"] = test_labels[ind]\n",
    "        summary[\"prediction\"] = pred_labels[ind]\n",
    "        test_result_summary.append(summary)\n",
    "\n",
    "    return test_cer_loss, test_result_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cer_loss, test_result_summary = evaluations(model, test_loader, label_encoder)\n",
    "print(f\"CharErrorRate: {test_cer_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity = 5\n",
    "test_result_summary = sorted(test_result_summary, key=lambda x: x[\"char_err\"], reverse=True)\n",
    "for img in test_result_summary[:quantity]:\n",
    "    print(f\"        Label: {img['label']}\\n   Prediction: {img['prediction']}\")\n",
    "    print(f\"CharErrorRate: {r4(img['char_err'])}\")\n",
    "    plt.imshow(img[\"data\"], cmap=\"gray\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
